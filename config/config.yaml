data:
  dataset_path: "rajpurkar/squad_v2"

training:
  model_name: "distilbert/distilbert-base-uncased"
  max_length: 384
  output_dir: "saved_models"
  learning_rate: 3e-5
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  num_train_epochs: 3
  weight_decay: 0.01
  warmup_ratio: 0.1
  logging_steps: 100
  evaluation_strategy: "steps"
  eval_steps: 500
  save_steps: 500
  save_total_limit: 3
  early_stopping_patience: 2 # Stop if no improvement for 2 evaluation calls
  early_stopping_threshold: 0.0 # Any improvement counts
  load_best_model_at_end: true


  seed: 42
  fp16: true

wandb:
  project: "squad_v2_qa"
  entity: "anadea" 
  run_name: distillbert-base-uncased-squad-v2
  API_TOKEN: "604b06640dbf9c0c8f0a0bfdb13eee93b84fd42b"
  



